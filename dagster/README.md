# Dagster Pipeline - Casa Teva

OrquestaciÃ³n de scrapers y ETL para el sistema de captaciÃ³n de leads inmobiliarios.

## ğŸ“ Estructura

```
dagster/
â”œâ”€â”€ workspace.yaml                           # ConfiguraciÃ³n del workspace
â””â”€â”€ casa_teva_pipeline/
    â”œâ”€â”€ __init__.py                         # Definitions principal
    â”œâ”€â”€ assets/
    â”‚   â””â”€â”€ scraping_assets.py              # Assets de scraping
    â”œâ”€â”€ resources/
    â”‚   â”œâ”€â”€ minio_resource.py               # Resource MinIO
    â”‚   â””â”€â”€ postgres_resource.py            # Resource PostgreSQL
    â””â”€â”€ schedules/
        â””â”€â”€ scraping_schedules.py           # Schedules automatizados
```

## ğŸš€ Inicio RÃ¡pido

### 1. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 2. Iniciar Dagster UI

```bash
cd dagster
dagster dev
```

La UI estarÃ¡ disponible en: http://localhost:3000

### 3. Ver assets y jobs

- Navega a la pestaÃ±a "Assets"
- VerÃ¡s todos los assets definidos con sus dependencias

### 4. Ejecutar manualmente

Desde la UI:
1. Ir a "Assets" â†’ Seleccionar assets
2. Click en "Materialize selected"

Desde CLI:
```bash
dagster asset materialize -m casa_teva_pipeline
```

## ğŸ“Š Assets Definidos

### **bronze_fotocasa_listings**
- Ejecuta scraper de Fotocasa
- Guarda JSONs en MinIO: `bronze/tenant_1/fotocasa/{fecha}/`
- **Output**: Metadata con nÃºmero de listings y paths

### **raw_postgres_listings**
- Depende de: `bronze_fotocasa_listings`
- Lee JSONs de MinIO
- Inserta en PostgreSQL: `raw.raw_listings`
- **Output**: NÃºmero de registros cargados

### **scraping_stats**
- Depende de: `raw_postgres_listings`
- Genera estadÃ­sticas consolidadas
- **Output**: Dict con mÃ©tricas de scraping

### **bronze_milanuncios_listings** (Placeholder)
- Por implementar cuando scraper estÃ© listo

### **bronze_wallapop_listings** (Placeholder)
- Por implementar cuando scraper estÃ© listo

## ğŸ”§ Resources

### **MinIOResource**
InteracciÃ³n con Data Lake (MinIO):
- `save_json()`: Guarda diccionarios como JSON
- `read_json()`: Lee archivos JSON
- `list_files()`: Lista archivos por prefijo
- `delete_file()`: Elimina archivos

**ConfiguraciÃ³n:**
```python
MinIOResource(
    endpoint="localhost:9000",
    access_key="minioadmin",
    secret_key="minioadmin",
    bucket_name="casa-teva-data-lake",
    secure=False
)
```

### **PostgresResource**
InteracciÃ³n con PostgreSQL:
- `execute_query()`: Ejecuta queries SQL
- `insert_data()`: Inserta registros
- `insert_raw_listing()`: Inserta en raw.raw_listings
- `bulk_insert_raw_listings()`: Inserta mÃºltiples registros
- `get_latest_scraping_timestamp()`: Obtiene Ãºltimo scraping

**ConfiguraciÃ³n:**
```python
PostgresResource(
    host="localhost",
    port=5432,
    database="casa_teva_db",
    user="casa_teva",
    password="casateva2024"
)
```

## â° Schedules

### **scraping_schedule** (Activo)
- **Cron**: `0 */6 * * *` (cada 6 horas)
- **Timezone**: Europe/Madrid
- **Horarios**: 00:00, 06:00, 12:00, 18:00
- **Estado**: RUNNING

### **scraping_schedule_hourly** (Inactivo)
- **Cron**: `0 * * * *` (cada hora)
- **Estado**: STOPPED (para testing)

### **scraping_schedule_daily** (Inactivo)
- **Cron**: `0 2 * * *` (2 AM diario)
- **Estado**: STOPPED

### **scraping_schedule_custom** (Inactivo)
- **LÃ³gica custom**: Solo dÃ­as laborables
- **Estado**: STOPPED

## ğŸ¯ Jobs

### **scraping_job**
- Ejecuta todos los assets de scraping
- Tags: team=data-engineering, priority=high

### **fotocasa_job**
- Solo ejecuta assets de Fotocasa
- Tags: portal=fotocasa

## ğŸ“ˆ Lineage de Datos

```
bronze_fotocasa_listings (MinIO)
    â†“
raw_postgres_listings (PostgreSQL)
    â†“
scraping_stats (MÃ©tricas)
```

## ğŸ”„ Flujo de EjecuciÃ³n

1. **Scraping** (`bronze_fotocasa_listings`)
   - Ejecuta `run_fotocasa_scraper.py --minio`
   - Scrapy + Playwright extrae listings
   - Guarda JSONs en MinIO bronze layer

2. **Carga** (`raw_postgres_listings`)
   - Lee todos los JSONs del dÃ­a
   - Bulk insert en PostgreSQL
   - Tabla: `raw.raw_listings`

3. **Reporting** (`scraping_stats`)
   - Consolida estadÃ­sticas
   - Metadata en Dagster UI

## ğŸ› ï¸ Comandos Ãštiles

### Verificar configuraciÃ³n
```bash
dagster dev --check
```

### Materializar asset especÃ­fico
```bash
dagster asset materialize -m casa_teva_pipeline -s bronze_fotocasa_listings
```

### Materializar todos los assets
```bash
dagster asset materialize -m casa_teva_pipeline
```

### Ver logs
```bash
# Los logs aparecen en la UI y en consola
dagster dev -v
```

### Activar/desactivar schedule desde CLI
```bash
dagster schedule start scraping_schedule
dagster schedule stop scraping_schedule
```

## ğŸ“ ConfiguraciÃ³n Personalizada

### Cambiar configuraciÃ³n de MinIO

Editar `casa_teva_pipeline/__init__.py`:

```python
resources = {
    "minio": MinIOResource(
        endpoint="minio.tudominio.com:9000",  # â† Cambiar
        access_key="tu_access_key",           # â† Cambiar
        secret_key="tu_secret_key",           # â† Cambiar
        bucket_name="mi-bucket",              # â† Cambiar
        secure=True,                          # â† Cambiar si usas HTTPS
    ),
    # ...
}
```

### Cambiar horarios de schedule

Editar `schedules/scraping_schedules.py`:

```python
scraping_schedule = ScheduleDefinition(
    name="scraping_schedule",
    cron_schedule="0 */4 * * *",  # â† Cambiar a cada 4 horas
    # ...
)
```

## ğŸ› Debugging

### Ver detalles de ejecuciÃ³n
1. Ir a "Runs" en la UI
2. Click en el run especÃ­fico
3. Ver logs, duraciÃ³n, metadata

### Ejecutar en modo debug
```bash
dagster dev --log-level debug
```

### Verificar assets sin ejecutar
```bash
dagster asset check -m casa_teva_pipeline
```

## ğŸ” Seguridad

**IMPORTANTE**: Las credenciales en `__init__.py` son para desarrollo.

Para producciÃ³n:
1. Usar variables de entorno
2. Usar secrets manager (AWS Secrets Manager, etc.)
3. Configurar con ConfigurableResource

Ejemplo con env vars:
```python
import os

resources = {
    "postgres": PostgresResource(
        password=os.getenv("POSTGRES_PASSWORD"),
        # ...
    ),
}
```

## ğŸ“Š Metadata y Observabilidad

Dagster trackea automÃ¡ticamente:
- âœ… Tiempo de ejecuciÃ³n de cada asset
- âœ… Metadata custom (num_listings, paths, etc.)
- âœ… Lineage de datos
- âœ… Versiones de assets
- âœ… Historial de runs

## ğŸš§ PrÃ³ximos Pasos

1. Implementar assets para Milanuncios y Wallapop
2. AÃ±adir sensors para ejecutar cuando aparezcan nuevos archivos
3. Implementar alertas (Slack, email)
4. AÃ±adir tests para assets
5. Configurar Dagster Cloud para producciÃ³n

## ğŸ“š DocumentaciÃ³n

- [Dagster Docs](https://docs.dagster.io/)
- [Asset Best Practices](https://docs.dagster.io/concepts/assets/software-defined-assets)
- [Schedule Guide](https://docs.dagster.io/concepts/partitions-schedules-sensors/schedules)
